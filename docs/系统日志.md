# 系统日志与 ELK 采集方案

本项目的系统日志设计旨在提供一套结构化、可聚合、可关联的日志解决方案，以便于快速定位问题、进行系统监控和行为分析。我们采用 **Pino** 输出结构化 JSON 日志，并通过 **ELK (Elasticsearch, Logstash/Vector, Kibana)** 栈进行收集、存储和可视化。

## 1. 设计目标

*   **结构化**: 输出标准 JSON 格式日志，易于机器解析和处理。
*   **标准化**: 日志字段遵循 **ECS (Elastic Common Schema)** 和 **OpenTelemetry (OTel)** 规范，确保与主流可观测性工具的兼容性。
*   **可聚合**: 方便将来自不同服务、不同容器的日志集中收集和查询。
*   **可关联**: 日志中包含 `trace.id` 和 `span.id`，可与全链路追踪数据进行关联，实现 Metrics -> Traces -> Logs 的无缝跳转。
*   **高效采集**: 利用 Docker 生态的优势，通过 Vector 高效采集容器日志。

## 2. 日志字段契约 (ECS/OTel 对齐)

系统日志使用 `nestjs-pino` 结合 `@elastic/ecs-pino-format` 输出结构化 JSON 到 `stdout`。以下是核心日志字段及其说明：

*   `service.name`: 服务名称 (e.g., `backend-nestjs`)。
*   `service.version`: 服务版本 (e.g., `dev`, `1.0.0`)。
*   `deployment.environment`: 部署环境 (e.g., `local`, `development`, `production`)。
*   `@timestamp`: 日志发生的时间戳 (ISO 8601 格式)。
*   `log.level`: 日志级别 (e.g., `info`, `warn`, `error`)。
*   `message`: 日志消息内容。
*   `http.request.method`: HTTP 请求方法 (e.g., `GET`, `POST`)。
*   `http.route`: **模板路由**。这是经过处理的路由路径，例如 `/api/users/:id`，而不是原始的 `/api/users/123`。这对于聚合和分析非常重要。
*   `http.response.status_code`: HTTP 响应状态码。
*   `event.duration`: 请求处理耗时，单位为纳秒 (ns)。
*   `trace.id`: OpenTelemetry Trace ID，用于全链路追踪。
*   `span.id`: OpenTelemetry Span ID，用于全链路追踪。
*   `request.id`: 请求的唯一 ID。
*   `client.ip`: 客户端 IP 地址。
*   `user_agent.original`: 客户端 User-Agent 字符串。
*   `user.id`: 操作用户 ID (可选)。
*   `user.name`: 操作用户名称 (可选)。

**重要原则**: `raw path` (原始请求路径，如 `/api/users/123`) 只允许进入 `url.path` 字段，禁止作为聚合字段，以避免高基数问题。

### `http.route` 获取规则

`http.route` 字段的准确性对于日志聚合和分析至关重要。其获取逻辑如下：

*   **优先使用 `req.baseUrl + req.route?.path`**: 当请求经过 NestJS 的路由匹配后，`req.route` 对象会包含路由模板信息。这是获取 `http.route` 的最佳方式。
*   **兜底使用 `Reflector` 拼接**: 如果 `req.route` 不可用，则通过 NestJS 的 `Reflector` 反射机制，拼接 Controller 的路径和 Handler 的路径，并保留 `:id` 等模板参数。
*   **最终兜底**: 如果以上方法都失败，则 `http.route` 会被设置为 `"unknown"`。
*   **禁止降级为原始路径**: 严禁将原始请求路径（如 `/api/users/123`）作为 `http.route` 的值，这会破坏聚合能力。

### `event.duration` 口径

请求处理耗时 `event.duration` 使用高精度时间源计算。建议基于 `process.hrtime.bigint()` 得到纳秒级的时间差，以确保精确性。

## 3. 脱敏策略

系统日志同样需要进行脱敏处理，以保护敏感信息。

*   **必脱敏路径示例**:
    *   `req.headers.authorization`
    *   `req.headers.cookie`
    *   `req.body.password`
    *   `req.body.token`
    *   `req.body.otpSecret`
    *   `req.body.refreshToken`
*   **访问日志**: 访问日志不记录完整的请求体 (`body`)，必要时只记录其长度或白名单字段，以避免日志量失控和敏感信息泄露。

## 4. `/operation-logs` 的处理原则

`操作日志` (Operation Logs) 和 `系统日志` (System Logs) 是两种不同类型的日志，它们有不同的目的和处理原则：

*   **操作日志**: 关注业务操作的审计，记录“谁在何时对什么做了什么”。
*   **系统日志**: 关注应用运行时的状态和错误，记录“系统发生了什么”。

为了避免重复记录和混淆，对于 `/operation-logs` 接口产生的日志：

*   **默认不丢弃**: 不会直接丢弃，而是将其分流到专门的 `audit` 数据集（例如，在 Vector 配置中将其 `event.dataset` 设置为 `audit` 或 `log.logger` 设置为 `audit`）。
*   **明确边界**: 审计日志与访问日志的边界必须明确，避免同一事件重复或互相覆盖。

## 5. ELK 采集方案详解

我们使用 Docker Compose 启动 ELK 栈，并通过 **Vector** 作为轻量级、高性能的日志采集器。

### 5.1. 启动 ELK 栈

在 `deploy/elk` 目录下，通过以下命令启动 ELK 服务：

```bash
docker compose -f deploy/elk/docker-compose.yml up -d
```

### 5.2. Vector 采集配置 (`deploy/elk/vector/vector.toml`)

Vector 的配置是日志采集的核心。

*   **Input (docker_logs)**: Vector 配置为直接通过 Docker Engine API 读取容器的 `stdout` 和 `stderr` 日志。
    ```toml
    [sources.docker_logs]
    type = "docker_logs"
    include_containers = ["backend"] # 仅采集 backend 容器的日志
    ```
*   **Parser (Pino JSON)**: 将 `backend` 输出的 Pino JSON 格式日志解析成结构化的事件。
    ```toml
    [transforms.parse_json]
    type = "remap"
    inputs = ["docker_logs"]
    source = '''
      . = parse_json!(.message)
      # 确保 @timestamp 字段存在且格式正确
      .@timestamp = to_timestamp!(.time)
      # 映射日志级别
      .log.level = .level
      # ... 其他字段映射
    '''
    ```
*   **Filter (降噪与分流)**:
    *   **降噪**: 可以配置 Vector 过滤掉 `OPTIONS` 请求或健康检查等无价值的日志。
    *   **分流**: 根据日志内容（例如 `http.route` 或 `log.logger`）将日志发送到不同的 Elasticsearch Data Stream。例如，将操作日志分流到 `logs-audit-default`。
*   **Output (Elasticsearch data stream)**: 将处理后的结构化日志发送到 Elasticsearch。
    ```toml
    [sinks.elasticsearch]
    type = "elasticsearch"
    inputs = ["parse_json"]
    endpoint = "http://elasticsearch:9200"
    index = "logs-system-default" # 或 logs-audit-default
    ```

### 5.3. Kibana 中创建 Data View

在 Kibana 中，您需要创建一个 `Data View` 来查询和可视化日志。

*   **Data View 模式**: 配置为 `logs-*`，这样可以同时匹配 `logs-system-default` 和 `logs-audit-default` 等数据流。
*   **字段刷新**: 确保刷新字段列表，以便 Kibana 识别所有结构化日志字段。

## 6. Metrics 约束 (Prometheus)

为了避免 Prometheus 存储过多的高基数数据，对 Metrics 的标签 (labels) 有严格约束：

*   **允许的标签**: 仅允许 `method`, `route`, `status_class` 等低基数字段作为标签。
*   **禁止的标签**: 严禁将 `path` (原始路径), `userId`, `requestId`, `username`, `ip` 等高基数字段作为标签。
*   **建议的 Buckets**: 对于 Histogram 类型的 Metrics，建议使用标准的 `buckets` 配置，例如 `0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10` 秒，以提供有意义的延迟分布。

## 7. Traces 采样原则

全链路追踪的采样策略旨在平衡数据量和可观测性：

*   **Head Sampling**: 在 SDK 侧进行采样，通常设置为 1%~5% 的请求进行全量追踪。
*   **Tail Sampling**: 在 Collector Gateway 侧进行采样，可以根据业务需求配置更复杂的策略，例如：
    *   始终保留所有包含错误的 Trace。
    *   始终保留所有耗时超过某个阈值（例如 1 秒）的 Trace。
    *   默认慢请求阈值可通过环境变量调整。

## 8. 本地开发时的日志查看

*   **后端以 Docker 方式运行时**: Vector 会通过 Docker API 自动采集容器的 `stdout` 日志，并发送到 ELK。
*   **后端直接本地运行时**: 日志会直接输出到终端。如果需要采集到 ELK，建议也通过 Docker 容器方式运行后端服务。
